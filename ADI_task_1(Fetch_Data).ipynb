{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADI task#1(Fetch_Data).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMs+dAGp5GcAiJM7fAXBblb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hendfekry/my_ml_server/blob/master/ADI_task_1(Fetch_Data).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fetch the data Task#1**\n"
      ],
      "metadata": {
        "id": "QycXun2N0Hyt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GhpfgOB5kfT",
        "outputId": "b0dd4721-83bc-4f64-85e5-86071ff9cfce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import glob"
      ],
      "metadata": {
        "id": "9o1gHW14501t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Wkb4oF2d559k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86052458-d080-4524-c120-140c4a01a7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#divided the csv file to smaller ones.\n",
        "source_path = \"/content/drive/MyDrive/dialect_dataset.csv\"\n",
        "df = pd.read_csv(source_path)\n",
        "for i,chunk in enumerate(pd.read_csv(source_path, chunksize=1000)):\n",
        "    chunk.to_csv('/content/drive/MyDrive/arabic_dialect/data_csv/chunk{}.csv'.format(i), index=False)"
      ],
      "metadata": {
        "id": "1FgSjLzb59xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the id column to string \n",
        "df=pd.read_csv(\"/content/drive/MyDrive/dialect_dataset.csv\")\n",
        "ID_int =df.id.to_list()\n",
        "ID_strings=[str(int) for int in ID_int]\n",
        "id=ID_strings\n"
      ],
      "metadata": {
        "id": "UbJsnrU29tdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creat a new csv file with ids as strings and convert it to json file\n",
        "\n",
        "id_dataframe=pd.DataFrame(id)\n",
        "id_dataframe.to_csv('id.csv',index=False)\n",
        "with open ('id.json','w') as file:\n",
        "  json.dump(id,file,indent=4)"
      ],
      "metadata": {
        "id": "KB6HpLTQ-AtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#divide the id.json files to smallar files\n",
        "with open('id.json') as infile:\n",
        "  o = json.load(infile)\n",
        "  chunkSize = 1000\n",
        "  for i in range(0, len(o), chunkSize):\n",
        "    with open('/content/drive/MyDrive/arabic_dialect/id_json_files/file_' + str(i//chunkSize) + '.json', 'w') as outfile:\n",
        "      json.dump(o[i:i+chunkSize], outfile)"
      ],
      "metadata": {
        "id": "AYByQf91-rJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fetch the data from the website\n",
        "url =\"https://recruitment.aimtechnologies.co/ai-tasks\"\n",
        "for i in range(0, len(o), chunkSize):\n",
        "  with open ('/content/drive/MyDrive/arabic_dialect/id_json_files/file_' + str(i//chunkSize) + '.json','r') as file:\n",
        "      data=json.load(file)\n",
        "      r=requests.post(url,json=data)\n",
        "\n",
        "  with open('/content/drive/MyDrive/arabic_dialect/id_with_text_json/r_'+ str(i//chunkSize) + '.json','w') as file:\n",
        "      json.dump(r.json(),file,indent=4)\n"
      ],
      "metadata": {
        "id": "GU35DE7j_VMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(o), chunkSize):\n",
        "  with open ('/content/drive/MyDrive/arabic_dialect/id_with_text_json/r_' + str(i//chunkSize) + '.json') as file:\n",
        "    df = pd.read_json(file,typ='dictionary')\n",
        "    df.to_frame('count')\n",
        "    df.to_csv('/content/drive/MyDrive/arabic_dialect/data_modified_csv/csvfile'+ str(i//chunkSize) + '.csv', index=False)\n"
      ],
      "metadata": {
        "id": "2agCuVo5Islr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files = os.path.join(\"/content/drive/MyDrive/arabic_dialect/data_modified_csv/\",\"csvfile*.csv\")\n",
        "files = glob.glob(files)\n",
        "for csv_file in files:\n",
        "  df=pd.read_csv(csv_file,lineterminator='\\n')\n",
        "  df.to_csv('master.csv',mode='a',header=False,index=False)\n"
      ],
      "metadata": {
        "id": "fznCeK6fDBNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_master=pd.read_csv(\"/content/drive/MyDrive/dialect_dataset.csv\")\n",
        "df_frame=pd.read_csv('master.csv',lineterminator='\\n')\n",
        "df_master[\"text\"]=df_frame\n",
        "df_master.to_csv('modified_with_text.csv',index=False)\n",
        "df=pd.read_csv('modified_with_text.csv',lineterminator='\\n')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOLUyTMdEgJo",
        "outputId": "ab7e30a2-3700-4c94-c36a-f0a314eeee91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    id dialect  \\\n",
            "0  1175358310087892992      IQ   \n",
            "1  1175416117793349632      IQ   \n",
            "2  1175450108898565888      IQ   \n",
            "3  1175471073770573824      IQ   \n",
            "4  1175496913145217024      IQ   \n",
            "\n",
            "                                                text  \n",
            "0  @7zNqXP0yrODdRjK ŸäÿπŸÜŸä Ÿáÿ∞ÿß ŸÖÿ≠ÿ≥Ÿàÿ® ÿπŸÑŸâ ÿßŸÑÿ®ÿ¥ÿ± .. ÿ≠...  \n",
            "1                    @KanaanRema ŸÖÿ®ŸäŸÜ ŸÖŸÜ ŸÉŸÑÿßŸÖŸá ÿÆŸÑŸäÿ¨Ÿä  \n",
            "2         @HAIDER76128900 Ÿäÿ≥ŸÑŸÖŸÑŸä ŸÖÿ±Ÿàÿ±ŸÉ Ÿàÿ±Ÿàÿ≠ŸÉ ÿßŸÑÿ≠ŸÑŸàŸáüíê  \n",
            "3                 @hmo2406 ŸàŸäŸÜ ŸáŸÑ ÿßŸÑÿ∫Ÿäÿ®Ÿá  ÿßÿÆ ŸÖÿ≠ŸÖÿØ üå∏üå∫  \n",
            "4  @Badi9595 @KanaanRema ŸäÿßÿßÿÆŸä ÿßŸÑÿ•ÿ±Ÿáÿßÿ®Ÿä ÿßÿ∞ÿß ŸÉÿßŸÜ ÿπ...  \n"
          ]
        }
      ]
    }
  ]
}